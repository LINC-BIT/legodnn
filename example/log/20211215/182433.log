2021-12-15 18:24:33,771 - log.py[38] - DEBUG: entry file content: ---------------------------------
2021-12-15 18:24:33,771 - log.py[39] - DEBUG: 
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import sys
sys.path.insert(0, r'.')
sys.setrecursionlimit(100000)

import torch
from legodnn import BlockTrainer, ServerBlockProfiler, EdgeBlockProfiler, OptimalRuntime
from legodnn.common.utils.dl.common.env import set_random_seed
set_random_seed(0)
from legodnn.common.manager.block_manager.auto_block_manager import AutoBlockManager
from legodnn.common.manager.model_manager.common_model_manager import CommonModelManager
from cv_task.image_classification.cifar.models import resnet18
from cv_task.datasets.image_classification.cifar_dataloader import CIFAR100Dataloader
if __name__ == '__main__':
    cv_task = 'image_classification'
    dataset_name = 'cifar100'
    model_name = 'resnet18'
    # compress_layer_max_ratio = 0.25
    compress_layer_max_ratio = 0.125
    device = 'cuda' 
    model_input_size = (1, 3, 32, 32)
    train_batch_size = 128
    test_batch_size = 128
    block_sparsity = [0.0, 0.3, 0.6, 0.8]
    root_path = os.path.join('../data/blocks', cv_task, model_name + '_' + dataset_name + '_' + str(compress_layer_max_ratio).replace('.', '-'))
    compressed_blocks_dir_path = root_path + '/compressed'
    trained_blocks_dir_path = root_path + '/trained'
    descendant_models_dir_path = root_path + '/descendant'
    block_training_max_epoch = 20
    test_sample_num = 100
    
    teacher_model = resnet18(num_classes=100).to(device)
    teacher_model.load_state_dict(torch.load('data/model/resnet18/2021-10-20/22-09-22/resnet18.pth')['net'])



    model_manager = CommonModelManager()
    block_manager = AutoBlockManager(block_sparsity,teacher_model,model_manager,model_input_size,compress_layer_max_ratio,device)
    
    print('\033[1;36m-------------------------------->    START BLOCK EXTRACTION\033[0m')

    block_manager.extract_all_blocks(compressed_blocks_dir_path)

    print('\033[1;36m-------------------------------->    START BLOCK TRAIN\033[0m')
    train_loader, test_loader = CIFAR100Dataloader()
    block_trainer = BlockTrainer(teacher_model, block_manager, model_manager, compressed_blocks_dir_path,
                                 trained_blocks_dir_path, block_training_max_epoch, train_loader, device=device)
    block_trainer.train_all_blocks()

    server_block_profiler = ServerBlockProfiler(teacher_model, block_manager, model_manager,
                                                trained_blocks_dir_path, test_loader, model_input_size, device)
    server_block_profiler.profile_all_blocks()


    edge_block_profiler = EdgeBlockProfiler(block_manager, model_manager, trained_blocks_dir_path,
                                            test_sample_num, model_input_size, device)
    edge_block_profiler.profile_all_blocks()

    optimal_runtime = OptimalRuntime(trained_blocks_dir_path, model_input_size,
                                     block_manager, model_manager, device)


2021-12-15 18:24:33,772 - log.py[40] - DEBUG: entry file content: ---------------------------------
2021-12-15 18:24:38,777 - auto_block_manager.py[234] - INFO: save pruned block block-0 (sparsity 0.0) in ../data/blocks\image_classification\resnet18_cifar100_0-125/compressed\block-0-0.pt
2021-12-15 18:24:38,777 - auto_block_manager.py[235] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2021-12-15 18:24:38,979 - auto_block_manager.py[234] - INFO: save pruned block block-0 (sparsity 0.3) in ../data/blocks\image_classification\resnet18_cifar100_0-125/compressed\block-0-3.pt
2021-12-15 18:24:38,979 - auto_block_manager.py[235] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(45, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2021-12-15 18:24:39,196 - auto_block_manager.py[234] - INFO: save pruned block block-0 (sparsity 0.6) in ../data/blocks\image_classification\resnet18_cifar100_0-125/compressed\block-0-6.pt
2021-12-15 18:24:39,196 - auto_block_manager.py[235] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
